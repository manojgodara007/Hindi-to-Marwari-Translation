{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dcc023a-37c6-4f24-8282-fd8070664ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87715303",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataorg = pd.read_csv(\"hintest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1adbdefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marwadi    0\n",
       "hindi      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(dataorg).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1f745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataorg = dataorg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a1c4316-c186-4af5-9437-0b305214c189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi_sentance</th>\n",
       "      <th>marwadi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अच्छा</td>\n",
       "      <td>आछौ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>आम</td>\n",
       "      <td>आंबौ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>आकाश</td>\n",
       "      <td>आब</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>बहुत दूर</td>\n",
       "      <td>फिर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>बचाओ!</td>\n",
       "      <td>बचा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>कूदो</td>\n",
       "      <td>कूद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>नमस्कार।</td>\n",
       "      <td>राम राम सा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>वाह-वाह!</td>\n",
       "      <td>वाह-वाह</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>समझे कि नहीं?</td>\n",
       "      <td>समझे मे आयो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>मैं ठीक हूँ।</td>\n",
       "      <td>मे चॉको हु</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hindi_sentance marwadi_sentence\n",
       "0          अच्छा              आछौ\n",
       "1             आम            आंबौ \n",
       "2           आकाश              आब \n",
       "3       बहुत दूर              फिर\n",
       "4          बचाओ!              बचा\n",
       "5           कूदो             कूद \n",
       "6       नमस्कार।       राम राम सा\n",
       "7       वाह-वाह!          वाह-वाह\n",
       "8  समझे कि नहीं?     समझे मे आयो \n",
       "9   मैं ठीक हूँ।       मे चॉको हु"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"hindi_sentance\"] = dataorg[\"hindi\"]\n",
    "data[\"marwadi_sentence\"] = dataorg[\"marwadi\"]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81533ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi_sentance</th>\n",
       "      <th>marwadi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>START_ अच्छा _END</td>\n",
       "      <td>आछौ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START_ आम _END</td>\n",
       "      <td>आंबौ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>START_ आकाश _END</td>\n",
       "      <td>आब</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>START_ बहुत दूर _END</td>\n",
       "      <td>फिर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>START_ बचाओ _END</td>\n",
       "      <td>बचा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>START_ तुम्हारी शादी कब हुई थी _END</td>\n",
       "      <td>थारी शादी हुगी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>START_ आप वहाँ जाएँगे क्या _END</td>\n",
       "      <td>थे बटे जावो काईं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>START_ हाँ मुझे यह बहुत पसंद है। _END</td>\n",
       "      <td>हा मन ए कल्डा चोखा लागे</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>START_ आपको लाईन में लगकर इंतेज़ार करना पड़ेगा...</td>\n",
       "      <td>थाने लाईन में लागर अढिकणो पङी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>START_ तुमने मुझे पागल कर दिया। _END</td>\n",
       "      <td>तु मन पागल कर दियो</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        hindi_sentance  \\\n",
       "0                                    START_ अच्छा _END   \n",
       "1                                       START_ आम _END   \n",
       "2                                     START_ आकाश _END   \n",
       "3                                 START_ बहुत दूर _END   \n",
       "4                                     START_ बचाओ _END   \n",
       "..                                                 ...   \n",
       "991                START_ तुम्हारी शादी कब हुई थी _END   \n",
       "992                    START_ आप वहाँ जाएँगे क्या _END   \n",
       "993              START_ हाँ मुझे यह बहुत पसंद है। _END   \n",
       "994  START_ आपको लाईन में लगकर इंतेज़ार करना पड़ेगा...   \n",
       "995               START_ तुमने मुझे पागल कर दिया। _END   \n",
       "\n",
       "                  marwadi_sentence  \n",
       "0                              आछौ  \n",
       "1                             आंबौ  \n",
       "2                               आब  \n",
       "3                              फिर  \n",
       "4                              बचा  \n",
       "..                             ...  \n",
       "991                 थारी शादी हुगी  \n",
       "992               थे बटे जावो काईं  \n",
       "993        हा मन ए कल्डा चोखा लागे  \n",
       "994  थाने लाईन में लागर अढिकणो पङी  \n",
       "995             तु मन पागल कर दियो  \n",
       "\n",
       "[993 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "956d7b79-6a0e-482d-89b9-6a3c7cfc2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 आछौ\n",
       "1                               आंबौ \n",
       "2                                 आब \n",
       "3                                 फिर\n",
       "4                                 बचा\n",
       "                    ...              \n",
       "991                   थारी शादी हुगी?\n",
       "992                 थे बटे जावो काईं?\n",
       "993          हा मन ए कल्डा चोखा लागे.\n",
       "994    थाने लाईन में लागर अढिकणो पङी.\n",
       "995               तु मन पागल कर दियो.\n",
       "Name: marwadi_sentence, Length: 993, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hindi_sentance\"].apply(lambda x: x.lower())\n",
    "data[\"marwadi_sentence\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "763d607c-c6bf-4bb3-a8ea-9d20e047591b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 आछौ\n",
       "1                               आंबौ \n",
       "2                                 आब \n",
       "3                                 फिर\n",
       "4                                 बचा\n",
       "                    ...              \n",
       "991                   थारी शादी हुगी?\n",
       "992                 थे बटे जावो काईं?\n",
       "993          हा मन ए कल्डा चोखा लागे.\n",
       "994    थाने लाईन में लागर अढिकणो पङी.\n",
       "995               तु मन पागल कर दियो.\n",
       "Name: marwadi_sentence, Length: 993, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hindi_sentance\"].apply(lambda x: re.sub(\"''\",'',x))\n",
    "data[\"marwadi_sentence\"].apply(lambda x: re.sub(\"''\",'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c357db92-4f03-42ef-8ad7-6e069d773a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "data['hindi_sentance']=data['hindi_sentance'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "data['marwadi_sentence']=data['marwadi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6aae30f3-046d-4d01-9794-9fff226deed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "data['hindi_sentance']=data['hindi_sentance'].apply(lambda x: x.translate(remove_digits))\n",
    "data['marwadi_sentence']=data['marwadi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "data['hindi_sentance'] = data['hindi_sentance'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "data['marwadi_sentence'] = data['marwadi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "data['hindi_sentance']=data['hindi_sentance'].apply(lambda x: x.strip())\n",
    "data['marwadi_sentence']=data['marwadi_sentence'].apply(lambda x: x.strip())\n",
    "data['hindi_sentance']=data['hindi_sentance'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "data['marwadi_sentence']=data['marwadi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8b6f75e-5a38-4139-8986-0185027e4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hindi_sentance'] = data['hindi_sentance'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4367761-de57-462d-9d42-fc61c4244890",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Hinid and Marwadi Vocabulary\n",
    "all_hin_words=set()\n",
    "for eng in data['hindi_sentance']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_hin_words:\n",
    "            all_hin_words.add(word)\n",
    "\n",
    "all_mar_words=set()\n",
    "for hind in data['marwadi_sentence']:\n",
    "    for word in hind.split():\n",
    "        if word not in all_mar_words:\n",
    "            all_mar_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f49db38-2847-4019-8851-ccb75679c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vocab = len(all_hin_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a156709-9c3e-4c91-9df1-484c26f0aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vocab = len(all_mar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3f53d28-12e9-40ee-9375-f6ccef3fd63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_HIN_LEN = 0\n",
    "for i in data[\"hindi_sentance\"]:\n",
    "    if len(i.split())>MAX_HIN_LEN:\n",
    "        MAX_HIN_LEN = len(i.split())\n",
    "MAX_HIN_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76fe74b2-46e2-4996-ab44-66ecc27b9690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_MAR_LEN = 0\n",
    "for i in data[\"marwadi_sentence\"]:\n",
    "    if len(i.split())>MAX_MAR_LEN:\n",
    "        MAX_MAR_LEN = len(i.split())\n",
    "MAX_MAR_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61c49208-bc97-4e52-b1c8-a8812168a3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_tokenizer = Tokenizer(num_words=x_vocab)\n",
    "x_tokenizer.fit_on_texts(data[\"hindi_sentance\"].values)\n",
    "X = x_tokenizer.texts_to_sequences(data[\"hindi_sentance\"].values)\n",
    "X = pad_sequences(X, maxlen=MAX_HIN_LEN, padding=\"post\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f3d8ece-ea13-4c5b-a327-c2c84646c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer = Tokenizer(num_words=y_vocab)\n",
    "y_tokenizer.fit_on_texts(data[\"marwadi_sentence\"].values)\n",
    "Y = y_tokenizer.texts_to_sequences(data[\"marwadi_sentence\"].values)\n",
    "Y = pad_sequences(Y, maxlen=MAX_MAR_LEN, padding=\"post\")\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ab27f40-38ce-4d27-a49d-cb08705470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(X, Y, train_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c240c8ea-bc93-468e-9ff1-4d7fae2ff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#making encoder model\n",
    "embedded_dim = 100\n",
    "latent_dim = 300\n",
    "\n",
    "encoder_input = Input(shape=(MAX_HIN_LEN,))\n",
    "encoder_emb_layer = Embedding(x_vocab, embedded_dim)\n",
    "encoder_emb = encoder_emb_layer(encoder_input)\n",
    "encoder_lstm = LSTM(latent_dim, recurrent_dropout=0.4, dropout=0.4, return_sequences=True, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder_lstm(encoder_emb)\n",
    "\n",
    "#decoding layer\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_emb_layer = Embedding(y_vocab, embedded_dim)\n",
    "decoder_emb = decoder_emb_layer(decoder_input)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab, activation=\"softmax\"))\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d08dd258-f7cb-413b-89d2-0111c3918a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b1d601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.2345 - accuracy: 0.0000e+00 - val_loss: 7.1983 - val_accuracy: 0.6460\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 7.1988 - accuracy: 0.6240 - val_loss: 7.1607 - val_accuracy: 0.6460\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 7.1620 - accuracy: 0.6240 - val_loss: 7.1018 - val_accuracy: 0.6460\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 7.1042 - accuracy: 0.6240 - val_loss: 6.9711 - val_accuracy: 0.6460\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 6.9770 - accuracy: 0.6240 - val_loss: 6.5030 - val_accuracy: 0.6460\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 6.5205 - accuracy: 0.6240 - val_loss: 4.6612 - val_accuracy: 0.6460\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 4.7223 - accuracy: 0.6240 - val_loss: 2.9548 - val_accuracy: 0.6460\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 3.0328 - accuracy: 0.6240 - val_loss: 2.7991 - val_accuracy: 0.6460\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.8299 - accuracy: 0.6240 - val_loss: 2.7440 - val_accuracy: 0.6460\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 2.7147 - accuracy: 0.6240 - val_loss: 2.7075 - val_accuracy: 0.6460\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 2.6328 - accuracy: 0.6240 - val_loss: 2.6866 - val_accuracy: 0.6460\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.5675 - accuracy: 0.6240 - val_loss: 2.6744 - val_accuracy: 0.6460\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 2.5083 - accuracy: 0.6240 - val_loss: 2.6684 - val_accuracy: 0.6460\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.4549 - accuracy: 0.6240 - val_loss: 2.6686 - val_accuracy: 0.6460\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.4050 - accuracy: 0.6240 - val_loss: 2.6760 - val_accuracy: 0.6460\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 2.3608 - accuracy: 0.6240 - val_loss: 2.6909 - val_accuracy: 0.6460\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 2.3254 - accuracy: 0.6240 - val_loss: 2.7397 - val_accuracy: 0.6460\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.3214 - accuracy: 0.6240 - val_loss: 2.8189 - val_accuracy: 0.6460\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.3734 - accuracy: 0.6240 - val_loss: 2.7569 - val_accuracy: 0.6460\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 2.2692 - accuracy: 0.6240 - val_loss: 2.7791 - val_accuracy: 0.6460\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 2.2549 - accuracy: 0.6240 - val_loss: 2.7852 - val_accuracy: 0.6460\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 2.2158 - accuracy: 0.6240 - val_loss: 2.8043 - val_accuracy: 0.6460\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 2.2060 - accuracy: 0.6240 - val_loss: 2.8283 - val_accuracy: 0.6460\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 2.1854 - accuracy: 0.6240 - val_loss: 2.8488 - val_accuracy: 0.6460\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 2.1893 - accuracy: 0.6240 - val_loss: 2.8736 - val_accuracy: 0.6444\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.1670 - accuracy: 0.6251 - val_loss: 2.8897 - val_accuracy: 0.6460\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.1769 - accuracy: 0.6240 - val_loss: 2.9057 - val_accuracy: 0.6444\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.1467 - accuracy: 0.6251 - val_loss: 2.9127 - val_accuracy: 0.6460\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.1479 - accuracy: 0.6240 - val_loss: 2.9322 - val_accuracy: 0.6444\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.1244 - accuracy: 0.6251 - val_loss: 2.9368 - val_accuracy: 0.6460\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 2.1258 - accuracy: 0.6240 - val_loss: 2.9619 - val_accuracy: 0.6407\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.1082 - accuracy: 0.6274 - val_loss: 2.9637 - val_accuracy: 0.6443\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.1104 - accuracy: 0.6251 - val_loss: 2.9898 - val_accuracy: 0.6417\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.0935 - accuracy: 0.6274 - val_loss: 2.9880 - val_accuracy: 0.6444\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 2.0946 - accuracy: 0.6251 - val_loss: 3.0172 - val_accuracy: 0.6417\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.0824 - accuracy: 0.6274 - val_loss: 3.0142 - val_accuracy: 0.6444\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.0876 - accuracy: 0.6251 - val_loss: 3.0431 - val_accuracy: 0.6417\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.0724 - accuracy: 0.6274 - val_loss: 3.0367 - val_accuracy: 0.6444\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 2.0787 - accuracy: 0.6251 - val_loss: 3.0661 - val_accuracy: 0.6417\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 2.0638 - accuracy: 0.6274 - val_loss: 3.0556 - val_accuracy: 0.6444\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 2.0688 - accuracy: 0.6251 - val_loss: 3.0842 - val_accuracy: 0.6417\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 2.0519 - accuracy: 0.6274 - val_loss: 3.0713 - val_accuracy: 0.6444\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 2.0528 - accuracy: 0.6251 - val_loss: 3.1009 - val_accuracy: 0.6417\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.0414 - accuracy: 0.6274 - val_loss: 3.0881 - val_accuracy: 0.6444\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.0436 - accuracy: 0.6251 - val_loss: 3.1189 - val_accuracy: 0.6417\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 2.0324 - accuracy: 0.6274 - val_loss: 3.1051 - val_accuracy: 0.6444\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 2.0344 - accuracy: 0.6251 - val_loss: 3.1381 - val_accuracy: 0.6417\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 2.0256 - accuracy: 0.6274 - val_loss: 3.1215 - val_accuracy: 0.6444\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 2.0293 - accuracy: 0.6251 - val_loss: 3.1561 - val_accuracy: 0.6417\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 2.0203 - accuracy: 0.6274 - val_loss: 3.1365 - val_accuracy: 0.6444\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.0229 - accuracy: 0.6251 - val_loss: 3.1710 - val_accuracy: 0.6417\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.0126 - accuracy: 0.6274 - val_loss: 3.1498 - val_accuracy: 0.6444\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 2.0139 - accuracy: 0.6251 - val_loss: 3.1840 - val_accuracy: 0.6428\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 2.0034 - accuracy: 0.6274 - val_loss: 3.1633 - val_accuracy: 0.6444\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.0064 - accuracy: 0.6251 - val_loss: 3.1985 - val_accuracy: 0.6428\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.9969 - accuracy: 0.6285 - val_loss: 3.1758 - val_accuracy: 0.6444\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.9985 - accuracy: 0.6251 - val_loss: 3.2106 - val_accuracy: 0.6428\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.9881 - accuracy: 0.6285 - val_loss: 3.1885 - val_accuracy: 0.6444\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.9917 - accuracy: 0.6251 - val_loss: 3.2258 - val_accuracy: 0.6428\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.9835 - accuracy: 0.6285 - val_loss: 3.2012 - val_accuracy: 0.6444\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.9865 - accuracy: 0.6251 - val_loss: 3.2383 - val_accuracy: 0.6428\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.9779 - accuracy: 0.6285 - val_loss: 3.2128 - val_accuracy: 0.6444\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.9802 - accuracy: 0.6263 - val_loss: 3.2527 - val_accuracy: 0.6428\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.9730 - accuracy: 0.6285 - val_loss: 3.2252 - val_accuracy: 0.6450\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 1.9766 - accuracy: 0.6251 - val_loss: 3.2650 - val_accuracy: 0.6428\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 1.9686 - accuracy: 0.6285 - val_loss: 3.2359 - val_accuracy: 0.6455\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 1.9711 - accuracy: 0.6285 - val_loss: 3.2750 - val_accuracy: 0.6428\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 1.9617 - accuracy: 0.6285 - val_loss: 3.2460 - val_accuracy: 0.6448\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.9644 - accuracy: 0.6263 - val_loss: 3.2856 - val_accuracy: 0.6428\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.9549 - accuracy: 0.6285 - val_loss: 3.2561 - val_accuracy: 0.6423\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.9561 - accuracy: 0.6263 - val_loss: 3.2953 - val_accuracy: 0.6428\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.9494 - accuracy: 0.6285 - val_loss: 3.2669 - val_accuracy: 0.6422\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 1.9510 - accuracy: 0.6285 - val_loss: 3.3067 - val_accuracy: 0.6428\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 1.9444 - accuracy: 0.6285 - val_loss: 3.2774 - val_accuracy: 0.6428\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 1.9464 - accuracy: 0.6274 - val_loss: 3.3185 - val_accuracy: 0.6428\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 1.9414 - accuracy: 0.6274 - val_loss: 3.2884 - val_accuracy: 0.6423\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.9459 - accuracy: 0.6308 - val_loss: 3.3322 - val_accuracy: 0.6427\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.9386 - accuracy: 0.6285 - val_loss: 3.2972 - val_accuracy: 0.6422\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 1.9408 - accuracy: 0.6296 - val_loss: 3.3404 - val_accuracy: 0.6429\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 1.9330 - accuracy: 0.6285 - val_loss: 3.3062 - val_accuracy: 0.6428\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 1.9353 - accuracy: 0.6263 - val_loss: 3.3506 - val_accuracy: 0.6429\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 1.9290 - accuracy: 0.6285 - val_loss: 3.3149 - val_accuracy: 0.6428\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.9288 - accuracy: 0.6274 - val_loss: 3.3578 - val_accuracy: 0.6427\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.9222 - accuracy: 0.6285 - val_loss: 3.3233 - val_accuracy: 0.6428\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.9215 - accuracy: 0.6285 - val_loss: 3.3660 - val_accuracy: 0.6426\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.9171 - accuracy: 0.6285 - val_loss: 3.3328 - val_accuracy: 0.6428\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 1.9195 - accuracy: 0.6285 - val_loss: 3.3775 - val_accuracy: 0.6427\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 1.9135 - accuracy: 0.6296 - val_loss: 3.3422 - val_accuracy: 0.6428\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.9162 - accuracy: 0.6296 - val_loss: 3.3888 - val_accuracy: 0.6424\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 1.9112 - accuracy: 0.6285 - val_loss: 3.3507 - val_accuracy: 0.6428\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 1.9127 - accuracy: 0.6296 - val_loss: 3.3986 - val_accuracy: 0.6404\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 1.9077 - accuracy: 0.6285 - val_loss: 3.3582 - val_accuracy: 0.6428\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 1.9080 - accuracy: 0.6285 - val_loss: 3.4049 - val_accuracy: 0.6406\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.9006 - accuracy: 0.6285 - val_loss: 3.3653 - val_accuracy: 0.6428\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.9011 - accuracy: 0.6285 - val_loss: 3.4137 - val_accuracy: 0.6404\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 1.8955 - accuracy: 0.6263 - val_loss: 3.3736 - val_accuracy: 0.6428\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.8976 - accuracy: 0.6274 - val_loss: 3.4239 - val_accuracy: 0.6383\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.8916 - accuracy: 0.6285 - val_loss: 3.3804 - val_accuracy: 0.6428\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 1.8933 - accuracy: 0.6274 - val_loss: 3.4349 - val_accuracy: 0.6322\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.8870 - accuracy: 0.6240 - val_loss: 3.3876 - val_accuracy: 0.6426\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.8911 - accuracy: 0.6285 - val_loss: 3.4498 - val_accuracy: 0.6225\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.8878 - accuracy: 0.6285 - val_loss: 3.3944 - val_accuracy: 0.6426\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 1.8905 - accuracy: 0.6274 - val_loss: 3.4578 - val_accuracy: 0.6227\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.8786 - accuracy: 0.6251 - val_loss: 3.3976 - val_accuracy: 0.6426\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.8809 - accuracy: 0.6296 - val_loss: 3.4678 - val_accuracy: 0.6223\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.8795 - accuracy: 0.6274 - val_loss: 3.4027 - val_accuracy: 0.6426\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.8781 - accuracy: 0.6296 - val_loss: 3.4860 - val_accuracy: 0.6212\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.8801 - accuracy: 0.6296 - val_loss: 3.4119 - val_accuracy: 0.6427\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 1.8694 - accuracy: 0.6285 - val_loss: 3.4711 - val_accuracy: 0.6235\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 1.8549 - accuracy: 0.6296 - val_loss: 3.4146 - val_accuracy: 0.6426\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.9288 - accuracy: 0.6195 - val_loss: 3.4861 - val_accuracy: 0.6216\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 1.8633 - accuracy: 0.6296 - val_loss: 3.4230 - val_accuracy: 0.6428\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.8547 - accuracy: 0.6285 - val_loss: 3.4771 - val_accuracy: 0.6238\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 1.8473 - accuracy: 0.6285 - val_loss: 3.4289 - val_accuracy: 0.6428\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.8425 - accuracy: 0.6296 - val_loss: 3.4870 - val_accuracy: 0.6234\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 1.8380 - accuracy: 0.6285 - val_loss: 3.4345 - val_accuracy: 0.6428\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.8374 - accuracy: 0.6296 - val_loss: 3.5110 - val_accuracy: 0.6222\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 1.8823 - accuracy: 0.6296 - val_loss: 3.4386 - val_accuracy: 0.6428\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.8477 - accuracy: 0.6285 - val_loss: 3.5059 - val_accuracy: 0.6219\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 1.8395 - accuracy: 0.6308 - val_loss: 3.4456 - val_accuracy: 0.6428\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 1.8380 - accuracy: 0.6296 - val_loss: 3.5236 - val_accuracy: 0.6216\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.8433 - accuracy: 0.6296 - val_loss: 3.4523 - val_accuracy: 0.6428\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.8483 - accuracy: 0.6296 - val_loss: 3.5464 - val_accuracy: 0.6213\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.8436 - accuracy: 0.6285 - val_loss: 3.4587 - val_accuracy: 0.6427\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 1.8444 - accuracy: 0.6319 - val_loss: 3.5548 - val_accuracy: 0.6212\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.8434 - accuracy: 0.6285 - val_loss: 3.4653 - val_accuracy: 0.6427\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.8334 - accuracy: 0.6296 - val_loss: 3.5543 - val_accuracy: 0.6229\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 1.8281 - accuracy: 0.6319 - val_loss: 3.4724 - val_accuracy: 0.6426\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 1.8210 - accuracy: 0.6285 - val_loss: 3.5512 - val_accuracy: 0.6219\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.8072 - accuracy: 0.6330 - val_loss: 3.4798 - val_accuracy: 0.6427\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 1.8067 - accuracy: 0.6308 - val_loss: 3.5610 - val_accuracy: 0.6230\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.8040 - accuracy: 0.6319 - val_loss: 3.4857 - val_accuracy: 0.6424\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 1.8123 - accuracy: 0.6308 - val_loss: 3.5967 - val_accuracy: 0.6216\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 1.8263 - accuracy: 0.6319 - val_loss: 3.4915 - val_accuracy: 0.6427\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 1.8417 - accuracy: 0.6319 - val_loss: 3.6250 - val_accuracy: 0.6206\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 1.8409 - accuracy: 0.6296 - val_loss: 3.4990 - val_accuracy: 0.6424\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.8250 - accuracy: 0.6319 - val_loss: 3.5971 - val_accuracy: 0.6218\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 1.8069 - accuracy: 0.6341 - val_loss: 3.5067 - val_accuracy: 0.6427\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.7943 - accuracy: 0.6319 - val_loss: 3.5905 - val_accuracy: 0.6219\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 1.7902 - accuracy: 0.6341 - val_loss: 3.5139 - val_accuracy: 0.6432\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 1.7863 - accuracy: 0.6319 - val_loss: 3.6062 - val_accuracy: 0.6213\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.7938 - accuracy: 0.6341 - val_loss: 3.5203 - val_accuracy: 0.6427\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.7921 - accuracy: 0.6308 - val_loss: 3.6273 - val_accuracy: 0.6211\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.7975 - accuracy: 0.6352 - val_loss: 3.5253 - val_accuracy: 0.6424\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.8011 - accuracy: 0.6319 - val_loss: 3.6386 - val_accuracy: 0.6203\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 1.7951 - accuracy: 0.6308 - val_loss: 3.5313 - val_accuracy: 0.6426\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 1.7968 - accuracy: 0.6319 - val_loss: 3.6466 - val_accuracy: 0.6203\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.7939 - accuracy: 0.6319 - val_loss: 3.5387 - val_accuracy: 0.6427\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.7835 - accuracy: 0.6308 - val_loss: 3.6429 - val_accuracy: 0.6208\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.7797 - accuracy: 0.6364 - val_loss: 3.5431 - val_accuracy: 0.6431\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 1.7784 - accuracy: 0.6319 - val_loss: 3.6458 - val_accuracy: 0.6213\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 1.7663 - accuracy: 0.6352 - val_loss: 3.5500 - val_accuracy: 0.6444\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.7638 - accuracy: 0.6319 - val_loss: 3.6608 - val_accuracy: 0.6203\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.7666 - accuracy: 0.6397 - val_loss: 3.5554 - val_accuracy: 0.6443\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.7729 - accuracy: 0.6330 - val_loss: 3.6815 - val_accuracy: 0.6174\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.7848 - accuracy: 0.6330 - val_loss: 3.5611 - val_accuracy: 0.6433\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.7768 - accuracy: 0.6308 - val_loss: 3.6890 - val_accuracy: 0.6170\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.7770 - accuracy: 0.6364 - val_loss: 3.5694 - val_accuracy: 0.6438\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.7575 - accuracy: 0.6308 - val_loss: 3.6785 - val_accuracy: 0.6203\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.7571 - accuracy: 0.6397 - val_loss: 3.5776 - val_accuracy: 0.6407\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.7408 - accuracy: 0.6330 - val_loss: 3.6793 - val_accuracy: 0.6198\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.7427 - accuracy: 0.6420 - val_loss: 3.5805 - val_accuracy: 0.6403\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.7430 - accuracy: 0.6341 - val_loss: 3.7010 - val_accuracy: 0.6157\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.7516 - accuracy: 0.6420 - val_loss: 3.5859 - val_accuracy: 0.6398\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.7494 - accuracy: 0.6330 - val_loss: 3.7287 - val_accuracy: 0.6085\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 1.7669 - accuracy: 0.6386 - val_loss: 3.5869 - val_accuracy: 0.6439\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 1.7765 - accuracy: 0.6330 - val_loss: 3.7539 - val_accuracy: 0.6038\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 1.7831 - accuracy: 0.6375 - val_loss: 3.5953 - val_accuracy: 0.6438\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.7530 - accuracy: 0.6330 - val_loss: 3.7121 - val_accuracy: 0.6191\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.7326 - accuracy: 0.6476 - val_loss: 3.6109 - val_accuracy: 0.6378\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.7195 - accuracy: 0.6352 - val_loss: 3.6950 - val_accuracy: 0.6204\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 1.7128 - accuracy: 0.6431 - val_loss: 3.6101 - val_accuracy: 0.6363\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.7154 - accuracy: 0.6352 - val_loss: 3.7292 - val_accuracy: 0.6117\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.7199 - accuracy: 0.6498 - val_loss: 3.6094 - val_accuracy: 0.6390\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 1.7302 - accuracy: 0.6330 - val_loss: 3.7636 - val_accuracy: 0.6023\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 1.7334 - accuracy: 0.6420 - val_loss: 3.6146 - val_accuracy: 0.6402\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.7407 - accuracy: 0.6341 - val_loss: 3.7710 - val_accuracy: 0.6038\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.7339 - accuracy: 0.6409 - val_loss: 3.6243 - val_accuracy: 0.6394\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 1.7246 - accuracy: 0.6330 - val_loss: 3.7637 - val_accuracy: 0.6085\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.7161 - accuracy: 0.6453 - val_loss: 3.6323 - val_accuracy: 0.6385\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.7110 - accuracy: 0.6341 - val_loss: 3.7583 - val_accuracy: 0.6106\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.6984 - accuracy: 0.6510 - val_loss: 3.6376 - val_accuracy: 0.6360\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.6991 - accuracy: 0.6341 - val_loss: 3.7684 - val_accuracy: 0.6075\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.7002 - accuracy: 0.6453 - val_loss: 3.6482 - val_accuracy: 0.6335\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.6864 - accuracy: 0.6341 - val_loss: 3.7694 - val_accuracy: 0.6087\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.6886 - accuracy: 0.6498 - val_loss: 3.6481 - val_accuracy: 0.6355\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.6936 - accuracy: 0.6330 - val_loss: 3.8093 - val_accuracy: 0.5986\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 1.7064 - accuracy: 0.6442 - val_loss: 3.6516 - val_accuracy: 0.6367\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 1.7117 - accuracy: 0.6330 - val_loss: 3.8215 - val_accuracy: 0.5976\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 1.7123 - accuracy: 0.6442 - val_loss: 3.6516 - val_accuracy: 0.6371\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.7094 - accuracy: 0.6330 - val_loss: 3.8127 - val_accuracy: 0.6005\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.6854 - accuracy: 0.6476 - val_loss: 3.6727 - val_accuracy: 0.6309\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 1.6857 - accuracy: 0.6341 - val_loss: 3.7911 - val_accuracy: 0.6092\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 1.6687 - accuracy: 0.6510 - val_loss: 3.6802 - val_accuracy: 0.6291\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.6649 - accuracy: 0.6386 - val_loss: 3.8074 - val_accuracy: 0.6050\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.6711 - accuracy: 0.6476 - val_loss: 3.6720 - val_accuracy: 0.6334\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 1.6773 - accuracy: 0.6352 - val_loss: 3.8499 - val_accuracy: 0.5957\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 1.6859 - accuracy: 0.6476 - val_loss: 3.6773 - val_accuracy: 0.6340\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 1.6942 - accuracy: 0.6341 - val_loss: 3.8580 - val_accuracy: 0.5956\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.6726 - accuracy: 0.6498 - val_loss: 3.6947 - val_accuracy: 0.6307\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.6642 - accuracy: 0.6330 - val_loss: 3.8214 - val_accuracy: 0.6070\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.6471 - accuracy: 0.6521 - val_loss: 3.6984 - val_accuracy: 0.6294\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.6440 - accuracy: 0.6364 - val_loss: 3.8348 - val_accuracy: 0.6038\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.6446 - accuracy: 0.6453 - val_loss: 3.6994 - val_accuracy: 0.6298\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 1.6419 - accuracy: 0.6364 - val_loss: 3.8512 - val_accuracy: 0.6000\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 1.6386 - accuracy: 0.6521 - val_loss: 3.7071 - val_accuracy: 0.6305\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 1.6437 - accuracy: 0.6364 - val_loss: 3.8738 - val_accuracy: 0.5972\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 1.6474 - accuracy: 0.6498 - val_loss: 3.6996 - val_accuracy: 0.6314\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 1.6508 - accuracy: 0.6352 - val_loss: 3.9008 - val_accuracy: 0.5941\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 1.6537 - accuracy: 0.6521 - val_loss: 3.7005 - val_accuracy: 0.6285\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 1.6392 - accuracy: 0.6364 - val_loss: 3.8689 - val_accuracy: 0.6019\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 1.6298 - accuracy: 0.6510 - val_loss: 3.7263 - val_accuracy: 0.6289\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.6199 - accuracy: 0.6375 - val_loss: 3.8710 - val_accuracy: 0.6000\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.6147 - accuracy: 0.6510 - val_loss: 3.7406 - val_accuracy: 0.6286\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.6034 - accuracy: 0.6364 - val_loss: 3.8716 - val_accuracy: 0.6019\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 1.6047 - accuracy: 0.6532 - val_loss: 3.7416 - val_accuracy: 0.6284\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 1.6019 - accuracy: 0.6386 - val_loss: 3.9080 - val_accuracy: 0.5972\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 1.6224 - accuracy: 0.6554 - val_loss: 3.7013 - val_accuracy: 0.6290\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 1.6428 - accuracy: 0.6352 - val_loss: 3.9500 - val_accuracy: 0.5926\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 1.6288 - accuracy: 0.6510 - val_loss: 3.7226 - val_accuracy: 0.6279\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 1.6171 - accuracy: 0.6375 - val_loss: 3.8947 - val_accuracy: 0.6039\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 1.5835 - accuracy: 0.6566 - val_loss: 3.7565 - val_accuracy: 0.6264\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 1.5732 - accuracy: 0.6453 - val_loss: 3.8774 - val_accuracy: 0.6079\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 1.5631 - accuracy: 0.6566 - val_loss: 3.7567 - val_accuracy: 0.6245\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.5626 - accuracy: 0.6476 - val_loss: 3.9104 - val_accuracy: 0.6055\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 1.5738 - accuracy: 0.6566 - val_loss: 3.7609 - val_accuracy: 0.6253\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 1.5720 - accuracy: 0.6397 - val_loss: 3.9299 - val_accuracy: 0.5993\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 1s 500ms/step - loss: 1.5767 - accuracy: 0.6543 - val_loss: 3.7322 - val_accuracy: 0.6285\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 1.5951 - accuracy: 0.6364 - val_loss: 3.9855 - val_accuracy: 0.5904\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.5980 - accuracy: 0.6453 - val_loss: 3.7502 - val_accuracy: 0.6276\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 1.5783 - accuracy: 0.6386 - val_loss: 3.9467 - val_accuracy: 0.5933\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.5778 - accuracy: 0.6476 - val_loss: 3.7763 - val_accuracy: 0.6317\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.5949 - accuracy: 0.6386 - val_loss: 3.9465 - val_accuracy: 0.5876\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 1.5695 - accuracy: 0.6476 - val_loss: 3.8065 - val_accuracy: 0.6289\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.5850 - accuracy: 0.6364 - val_loss: 3.9506 - val_accuracy: 0.5989\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 1.5366 - accuracy: 0.6577 - val_loss: 3.7818 - val_accuracy: 0.6270\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.5420 - accuracy: 0.6442 - val_loss: 3.9983 - val_accuracy: 0.5958\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 1.5668 - accuracy: 0.6521 - val_loss: 3.7492 - val_accuracy: 0.6257\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 1.5843 - accuracy: 0.6397 - val_loss: 4.0336 - val_accuracy: 0.5941\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.5981 - accuracy: 0.6510 - val_loss: 3.7982 - val_accuracy: 0.6278\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.5515 - accuracy: 0.6420 - val_loss: 3.9649 - val_accuracy: 0.5983\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 1.5270 - accuracy: 0.6554 - val_loss: 3.8313 - val_accuracy: 0.6243\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.5111 - accuracy: 0.6453 - val_loss: 3.9301 - val_accuracy: 0.6042\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 1.5046 - accuracy: 0.6543 - val_loss: 3.8308 - val_accuracy: 0.6230\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 1.5092 - accuracy: 0.6510 - val_loss: 3.9673 - val_accuracy: 0.5992\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.5119 - accuracy: 0.6577 - val_loss: 3.7959 - val_accuracy: 0.6274\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 1.5253 - accuracy: 0.6453 - val_loss: 4.0466 - val_accuracy: 0.5915\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 1.5472 - accuracy: 0.6521 - val_loss: 3.7354 - val_accuracy: 0.6250\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 1.5876 - accuracy: 0.6420 - val_loss: 4.0594 - val_accuracy: 0.5968\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.5804 - accuracy: 0.6554 - val_loss: 3.8399 - val_accuracy: 0.6252\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.5146 - accuracy: 0.6453 - val_loss: 3.9876 - val_accuracy: 0.5987\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 1.5002 - accuracy: 0.6510 - val_loss: 3.8499 - val_accuracy: 0.6258\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 1.4924 - accuracy: 0.6465 - val_loss: 3.9684 - val_accuracy: 0.6002\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 1.4863 - accuracy: 0.6543 - val_loss: 3.8773 - val_accuracy: 0.6219\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.4795 - accuracy: 0.6498 - val_loss: 3.9795 - val_accuracy: 0.6002\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 1.4730 - accuracy: 0.6599 - val_loss: 3.8704 - val_accuracy: 0.6229\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 1.4837 - accuracy: 0.6510 - val_loss: 4.0140 - val_accuracy: 0.5966\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.4912 - accuracy: 0.6588 - val_loss: 3.8516 - val_accuracy: 0.6274\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 1.4983 - accuracy: 0.6476 - val_loss: 4.0642 - val_accuracy: 0.5928\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 1.4931 - accuracy: 0.6554 - val_loss: 3.8021 - val_accuracy: 0.6263\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 1.5256 - accuracy: 0.6431 - val_loss: 4.1672 - val_accuracy: 0.5864\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.5829 - accuracy: 0.6510 - val_loss: 3.8525 - val_accuracy: 0.6253\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.5122 - accuracy: 0.6442 - val_loss: 4.0663 - val_accuracy: 0.5991\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 1.4788 - accuracy: 0.6554 - val_loss: 3.8680 - val_accuracy: 0.6211\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 1.4795 - accuracy: 0.6566 - val_loss: 4.0553 - val_accuracy: 0.6002\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 1.4602 - accuracy: 0.6566 - val_loss: 3.9019 - val_accuracy: 0.6184\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 1.4522 - accuracy: 0.6577 - val_loss: 4.0292 - val_accuracy: 0.6033\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.4421 - accuracy: 0.6633 - val_loss: 3.9083 - val_accuracy: 0.6167\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 1.4448 - accuracy: 0.6611 - val_loss: 4.0463 - val_accuracy: 0.6056\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.4599 - accuracy: 0.6566 - val_loss: 3.9154 - val_accuracy: 0.6130\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.4636 - accuracy: 0.6599 - val_loss: 4.0917 - val_accuracy: 0.6028\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.4941 - accuracy: 0.6577 - val_loss: 3.9320 - val_accuracy: 0.6171\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.4507 - accuracy: 0.6566 - val_loss: 4.0929 - val_accuracy: 0.5999\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.4439 - accuracy: 0.6588 - val_loss: 3.9009 - val_accuracy: 0.6212\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.4498 - accuracy: 0.6566 - val_loss: 4.1390 - val_accuracy: 0.5915\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 1.4646 - accuracy: 0.6554 - val_loss: 3.8598 - val_accuracy: 0.6285\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.5143 - accuracy: 0.6397 - val_loss: 4.1631 - val_accuracy: 0.5856\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.4896 - accuracy: 0.6554 - val_loss: 3.8570 - val_accuracy: 0.6278\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.4922 - accuracy: 0.6453 - val_loss: 4.1187 - val_accuracy: 0.5955\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.4403 - accuracy: 0.6588 - val_loss: 3.9166 - val_accuracy: 0.6194\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 1.4329 - accuracy: 0.6510 - val_loss: 4.0937 - val_accuracy: 0.6010\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 1.4161 - accuracy: 0.6577 - val_loss: 3.9626 - val_accuracy: 0.6127\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.4102 - accuracy: 0.6599 - val_loss: 4.0983 - val_accuracy: 0.6045\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.4318 - accuracy: 0.6566 - val_loss: 3.9500 - val_accuracy: 0.6119\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.4390 - accuracy: 0.6622 - val_loss: 4.1633 - val_accuracy: 0.6003\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.4990 - accuracy: 0.6566 - val_loss: 3.9639 - val_accuracy: 0.6178\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.4335 - accuracy: 0.6510 - val_loss: 4.1570 - val_accuracy: 0.5973\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.4205 - accuracy: 0.6599 - val_loss: 3.9645 - val_accuracy: 0.6189\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 1.4238 - accuracy: 0.6577 - val_loss: 4.1609 - val_accuracy: 0.5953\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 1.4255 - accuracy: 0.6622 - val_loss: 3.9436 - val_accuracy: 0.6228\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.4417 - accuracy: 0.6487 - val_loss: 4.1450 - val_accuracy: 0.5932\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.4121 - accuracy: 0.6588 - val_loss: 3.9885 - val_accuracy: 0.6193\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 1.4092 - accuracy: 0.6577 - val_loss: 4.1144 - val_accuracy: 0.5978\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.4004 - accuracy: 0.6599 - val_loss: 4.0032 - val_accuracy: 0.6196\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.3914 - accuracy: 0.6599 - val_loss: 4.1063 - val_accuracy: 0.6003\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.3836 - accuracy: 0.6588 - val_loss: 3.9996 - val_accuracy: 0.6186\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.3838 - accuracy: 0.6577 - val_loss: 4.1346 - val_accuracy: 0.5999\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.3775 - accuracy: 0.6622 - val_loss: 3.9403 - val_accuracy: 0.6194\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.4159 - accuracy: 0.6577 - val_loss: 4.3202 - val_accuracy: 0.5871\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.5310 - accuracy: 0.6566 - val_loss: 3.8680 - val_accuracy: 0.6240\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.5567 - accuracy: 0.6431 - val_loss: 4.2593 - val_accuracy: 0.5959\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.4830 - accuracy: 0.6532 - val_loss: 4.0746 - val_accuracy: 0.6136\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 1.3830 - accuracy: 0.6599 - val_loss: 4.1377 - val_accuracy: 0.6039\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.3677 - accuracy: 0.6611 - val_loss: 4.0732 - val_accuracy: 0.6126\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.3580 - accuracy: 0.6566 - val_loss: 4.1373 - val_accuracy: 0.6032\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.3541 - accuracy: 0.6566 - val_loss: 4.0678 - val_accuracy: 0.6141\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.3683 - accuracy: 0.6599 - val_loss: 4.1776 - val_accuracy: 0.5973\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.3740 - accuracy: 0.6599 - val_loss: 4.0449 - val_accuracy: 0.6192\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 1.3784 - accuracy: 0.6521 - val_loss: 4.2053 - val_accuracy: 0.5928\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.3945 - accuracy: 0.6577 - val_loss: 4.0138 - val_accuracy: 0.6213\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.3993 - accuracy: 0.6476 - val_loss: 4.1987 - val_accuracy: 0.5959\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.3706 - accuracy: 0.6622 - val_loss: 4.0408 - val_accuracy: 0.6178\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.3514 - accuracy: 0.6644 - val_loss: 4.1788 - val_accuracy: 0.6009\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.3461 - accuracy: 0.6622 - val_loss: 4.0376 - val_accuracy: 0.6142\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.3657 - accuracy: 0.6622 - val_loss: 4.2943 - val_accuracy: 0.5972\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.4286 - accuracy: 0.6633 - val_loss: 4.0060 - val_accuracy: 0.6178\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 1.4014 - accuracy: 0.6588 - val_loss: 4.3148 - val_accuracy: 0.5946\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.4317 - accuracy: 0.6566 - val_loss: 4.0719 - val_accuracy: 0.6161\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.3602 - accuracy: 0.6577 - val_loss: 4.2201 - val_accuracy: 0.6004\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.3474 - accuracy: 0.6622 - val_loss: 4.0911 - val_accuracy: 0.6146\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 1.3377 - accuracy: 0.6700 - val_loss: 4.2051 - val_accuracy: 0.6019\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.3250 - accuracy: 0.6655 - val_loss: 4.1286 - val_accuracy: 0.6104\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.3187 - accuracy: 0.6667 - val_loss: 4.1757 - val_accuracy: 0.6054\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 1.3209 - accuracy: 0.6667 - val_loss: 4.0939 - val_accuracy: 0.6146\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.3290 - accuracy: 0.6611 - val_loss: 4.2538 - val_accuracy: 0.5966\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.3477 - accuracy: 0.6700 - val_loss: 4.0276 - val_accuracy: 0.6206\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.3811 - accuracy: 0.6543 - val_loss: 4.3814 - val_accuracy: 0.5863\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 1.4262 - accuracy: 0.6543 - val_loss: 3.9787 - val_accuracy: 0.6229\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.4560 - accuracy: 0.6476 - val_loss: 4.3445 - val_accuracy: 0.5950\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.4188 - accuracy: 0.6554 - val_loss: 4.1004 - val_accuracy: 0.6160\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 1.3271 - accuracy: 0.6667 - val_loss: 4.1983 - val_accuracy: 0.6025\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.3086 - accuracy: 0.6633 - val_loss: 4.1513 - val_accuracy: 0.6087\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1.3008 - accuracy: 0.6723 - val_loss: 4.1821 - val_accuracy: 0.6078\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.2979 - accuracy: 0.6655 - val_loss: 4.1771 - val_accuracy: 0.6058\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 1.2957 - accuracy: 0.6689 - val_loss: 4.1829 - val_accuracy: 0.6097\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 1.2959 - accuracy: 0.6611 - val_loss: 4.1787 - val_accuracy: 0.6010\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 1.3105 - accuracy: 0.6689 - val_loss: 4.2329 - val_accuracy: 0.6095\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 1.3558 - accuracy: 0.6566 - val_loss: 4.1777 - val_accuracy: 0.6040\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 1.3377 - accuracy: 0.6667 - val_loss: 4.2522 - val_accuracy: 0.6091\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.3612 - accuracy: 0.6532 - val_loss: 4.1775 - val_accuracy: 0.6094\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.3065 - accuracy: 0.6700 - val_loss: 4.2453 - val_accuracy: 0.6055\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 1.2941 - accuracy: 0.6622 - val_loss: 4.1289 - val_accuracy: 0.6132\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 1.3087 - accuracy: 0.6689 - val_loss: 4.3478 - val_accuracy: 0.5943\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 1.3439 - accuracy: 0.6599 - val_loss: 4.0631 - val_accuracy: 0.6207\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.4051 - accuracy: 0.6554 - val_loss: 4.4460 - val_accuracy: 0.5844\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.4122 - accuracy: 0.6611 - val_loss: 4.0721 - val_accuracy: 0.6218\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.3801 - accuracy: 0.6543 - val_loss: 4.2929 - val_accuracy: 0.5968\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 1.3085 - accuracy: 0.6633 - val_loss: 4.2002 - val_accuracy: 0.6121\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.2833 - accuracy: 0.6599 - val_loss: 4.2230 - val_accuracy: 0.6038\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 1.2828 - accuracy: 0.6689 - val_loss: 4.2485 - val_accuracy: 0.6079\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.2887 - accuracy: 0.6622 - val_loss: 4.1829 - val_accuracy: 0.6087\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.2868 - accuracy: 0.6712 - val_loss: 4.2825 - val_accuracy: 0.6060\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 1.3128 - accuracy: 0.6599 - val_loss: 4.1821 - val_accuracy: 0.6053\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.3183 - accuracy: 0.6700 - val_loss: 4.3175 - val_accuracy: 0.6045\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 1.3428 - accuracy: 0.6543 - val_loss: 4.1695 - val_accuracy: 0.6125\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.2794 - accuracy: 0.6745 - val_loss: 4.2877 - val_accuracy: 0.6023\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.2693 - accuracy: 0.6667 - val_loss: 4.1778 - val_accuracy: 0.6125\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.2732 - accuracy: 0.6655 - val_loss: 4.3274 - val_accuracy: 0.5992\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 1.2839 - accuracy: 0.6667 - val_loss: 4.1367 - val_accuracy: 0.6146\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 1.3097 - accuracy: 0.6611 - val_loss: 4.4474 - val_accuracy: 0.5851\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.3721 - accuracy: 0.6611 - val_loss: 4.0877 - val_accuracy: 0.6198\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 1.3763 - accuracy: 0.6521 - val_loss: 4.3906 - val_accuracy: 0.5931\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.3231 - accuracy: 0.6622 - val_loss: 4.1629 - val_accuracy: 0.6148\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.2800 - accuracy: 0.6667 - val_loss: 4.3010 - val_accuracy: 0.6007\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.2640 - accuracy: 0.6667 - val_loss: 4.2189 - val_accuracy: 0.6109\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 1.2533 - accuracy: 0.6678 - val_loss: 4.2746 - val_accuracy: 0.6002\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.2590 - accuracy: 0.6700 - val_loss: 4.2507 - val_accuracy: 0.6124\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.2647 - accuracy: 0.6655 - val_loss: 4.2536 - val_accuracy: 0.6005\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 1.2769 - accuracy: 0.6678 - val_loss: 4.3009 - val_accuracy: 0.6085\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 1.3212 - accuracy: 0.6577 - val_loss: 4.1927 - val_accuracy: 0.6087\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 1.2845 - accuracy: 0.6633 - val_loss: 4.4011 - val_accuracy: 0.5986\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.3245 - accuracy: 0.6667 - val_loss: 4.2203 - val_accuracy: 0.6141\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 1.2728 - accuracy: 0.6734 - val_loss: 4.3869 - val_accuracy: 0.5966\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 1.2747 - accuracy: 0.6678 - val_loss: 4.1895 - val_accuracy: 0.6127\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 1.2994 - accuracy: 0.6633 - val_loss: 4.4489 - val_accuracy: 0.5901\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.2946 - accuracy: 0.6655 - val_loss: 4.2039 - val_accuracy: 0.6143\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.2729 - accuracy: 0.6633 - val_loss: 4.3797 - val_accuracy: 0.5951\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 1.2461 - accuracy: 0.6768 - val_loss: 4.2325 - val_accuracy: 0.6129\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 1.2435 - accuracy: 0.6700 - val_loss: 4.3714 - val_accuracy: 0.5988\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.2416 - accuracy: 0.6644 - val_loss: 4.2537 - val_accuracy: 0.6061\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 1.2463 - accuracy: 0.6745 - val_loss: 4.3591 - val_accuracy: 0.6060\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.2761 - accuracy: 0.6633 - val_loss: 4.2640 - val_accuracy: 0.6064\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 1.2463 - accuracy: 0.6734 - val_loss: 4.3936 - val_accuracy: 0.6000\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 1.2655 - accuracy: 0.6655 - val_loss: 4.2364 - val_accuracy: 0.6099\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.2493 - accuracy: 0.6712 - val_loss: 4.4318 - val_accuracy: 0.5953\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 1.2596 - accuracy: 0.6667 - val_loss: 4.2182 - val_accuracy: 0.6132\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 1.2700 - accuracy: 0.6678 - val_loss: 4.4730 - val_accuracy: 0.5895\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 1.2828 - accuracy: 0.6644 - val_loss: 4.1938 - val_accuracy: 0.6160\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 1.2717 - accuracy: 0.6633 - val_loss: 4.4283 - val_accuracy: 0.5931\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 1.2410 - accuracy: 0.6756 - val_loss: 4.2426 - val_accuracy: 0.6121\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 1.2352 - accuracy: 0.6734 - val_loss: 4.3930 - val_accuracy: 0.5996\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 1.2191 - accuracy: 0.6723 - val_loss: 4.2622 - val_accuracy: 0.6076\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 1.2110 - accuracy: 0.6768 - val_loss: 4.4028 - val_accuracy: 0.5996\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 1.2283 - accuracy: 0.6655 - val_loss: 4.2579 - val_accuracy: 0.6065\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 1.2476 - accuracy: 0.6678 - val_loss: 4.4419 - val_accuracy: 0.5984\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 1.2817 - accuracy: 0.6633 - val_loss: 4.3211 - val_accuracy: 0.6040\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 1.2420 - accuracy: 0.6712 - val_loss: 4.3852 - val_accuracy: 0.6054\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 1.2329 - accuracy: 0.6667 - val_loss: 4.3949 - val_accuracy: 0.5959\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 1.2257 - accuracy: 0.6779 - val_loss: 4.3165 - val_accuracy: 0.6122\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 1.2392 - accuracy: 0.6633 - val_loss: 4.4267 - val_accuracy: 0.5915\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 1.2479 - accuracy: 0.6678 - val_loss: 4.2698 - val_accuracy: 0.6178\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 1.2208 - accuracy: 0.6644 - val_loss: 4.4135 - val_accuracy: 0.5948\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 1.2076 - accuracy: 0.6779 - val_loss: 4.3175 - val_accuracy: 0.6112\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.1744 - accuracy: 0.6700 - val_loss: 4.3982 - val_accuracy: 0.6020\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.1771 - accuracy: 0.6813 - val_loss: 4.2892 - val_accuracy: 0.6092\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 1.2072 - accuracy: 0.6768 - val_loss: 4.5367 - val_accuracy: 0.5941\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 1.3214 - accuracy: 0.6667 - val_loss: 4.2502 - val_accuracy: 0.6120\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 1.2847 - accuracy: 0.6611 - val_loss: 4.5561 - val_accuracy: 0.5885\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 1.2608 - accuracy: 0.6644 - val_loss: 4.2809 - val_accuracy: 0.6097\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 1.2142 - accuracy: 0.6779 - val_loss: 4.4637 - val_accuracy: 0.5976\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 1.1887 - accuracy: 0.6756 - val_loss: 4.3603 - val_accuracy: 0.6043\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 1.1693 - accuracy: 0.6824 - val_loss: 4.4034 - val_accuracy: 0.6056\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 1.1811 - accuracy: 0.6745 - val_loss: 4.4174 - val_accuracy: 0.5963\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 1.1880 - accuracy: 0.6790 - val_loss: 4.3832 - val_accuracy: 0.6095\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 1.2093 - accuracy: 0.6700 - val_loss: 4.3774 - val_accuracy: 0.6008\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 1.2072 - accuracy: 0.6745 - val_loss: 4.4208 - val_accuracy: 0.6061\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.2085 - accuracy: 0.6723 - val_loss: 4.3920 - val_accuracy: 0.6023\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 1.1549 - accuracy: 0.6801 - val_loss: 4.3930 - val_accuracy: 0.6076\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 1.1461 - accuracy: 0.6790 - val_loss: 4.4151 - val_accuracy: 0.6008\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 1.1451 - accuracy: 0.6857 - val_loss: 4.3866 - val_accuracy: 0.6102\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 1.1493 - accuracy: 0.6768 - val_loss: 4.3905 - val_accuracy: 0.6018\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 1.1701 - accuracy: 0.6813 - val_loss: 4.4263 - val_accuracy: 0.6083\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 1.2023 - accuracy: 0.6667 - val_loss: 4.4168 - val_accuracy: 0.5974\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 1.2235 - accuracy: 0.6689 - val_loss: 4.4653 - val_accuracy: 0.6042\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 1.2497 - accuracy: 0.6622 - val_loss: 4.3898 - val_accuracy: 0.6048\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 1.1878 - accuracy: 0.6756 - val_loss: 4.5025 - val_accuracy: 0.5972\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 1.1710 - accuracy: 0.6846 - val_loss: 4.3255 - val_accuracy: 0.6126\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 1.1777 - accuracy: 0.6756 - val_loss: 4.6346 - val_accuracy: 0.5803\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 1.2353 - accuracy: 0.6667 - val_loss: 4.2875 - val_accuracy: 0.6155\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.2571 - accuracy: 0.6633 - val_loss: 4.5889 - val_accuracy: 0.5851\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 1.2056 - accuracy: 0.6712 - val_loss: 4.3464 - val_accuracy: 0.6120\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 1.1650 - accuracy: 0.6745 - val_loss: 4.4921 - val_accuracy: 0.5962\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 1.1255 - accuracy: 0.6880 - val_loss: 4.4038 - val_accuracy: 0.6063\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 1.1149 - accuracy: 0.6891 - val_loss: 4.4800 - val_accuracy: 0.5992\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 1.1160 - accuracy: 0.6981 - val_loss: 4.4033 - val_accuracy: 0.6084\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 1.1198 - accuracy: 0.6835 - val_loss: 4.5205 - val_accuracy: 0.5948\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 1.1239 - accuracy: 0.6846 - val_loss: 4.3961 - val_accuracy: 0.6099\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 1.1226 - accuracy: 0.6857 - val_loss: 4.5232 - val_accuracy: 0.5967\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 1.1328 - accuracy: 0.6835 - val_loss: 4.3582 - val_accuracy: 0.6075\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 1.1686 - accuracy: 0.6723 - val_loss: 4.5991 - val_accuracy: 0.5921\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.2284 - accuracy: 0.6678 - val_loss: 4.3771 - val_accuracy: 0.6087\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 1.1932 - accuracy: 0.6734 - val_loss: 4.5515 - val_accuracy: 0.5973\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 1.2140 - accuracy: 0.6723 - val_loss: 4.4586 - val_accuracy: 0.5992\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.1609 - accuracy: 0.6824 - val_loss: 4.4824 - val_accuracy: 0.6055\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 1.1515 - accuracy: 0.6700 - val_loss: 4.5280 - val_accuracy: 0.5935\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.1438 - accuracy: 0.6846 - val_loss: 4.4246 - val_accuracy: 0.6094\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.1216 - accuracy: 0.6756 - val_loss: 4.5389 - val_accuracy: 0.5931\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 1.1216 - accuracy: 0.6936 - val_loss: 4.4056 - val_accuracy: 0.6112\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.1070 - accuracy: 0.6891 - val_loss: 4.5646 - val_accuracy: 0.5909\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 1.1158 - accuracy: 0.6936 - val_loss: 4.3949 - val_accuracy: 0.6114\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 1.1098 - accuracy: 0.6824 - val_loss: 4.5819 - val_accuracy: 0.5913\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 1.1197 - accuracy: 0.6869 - val_loss: 4.3853 - val_accuracy: 0.6110\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 1.1288 - accuracy: 0.6779 - val_loss: 4.6279 - val_accuracy: 0.5901\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 1.1511 - accuracy: 0.6824 - val_loss: 4.3874 - val_accuracy: 0.6095\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 1.1641 - accuracy: 0.6779 - val_loss: 4.6200 - val_accuracy: 0.5920\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 1.1312 - accuracy: 0.6835 - val_loss: 4.4324 - val_accuracy: 0.6050\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 1.0953 - accuracy: 0.6902 - val_loss: 4.5646 - val_accuracy: 0.5971\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 1.0936 - accuracy: 0.6891 - val_loss: 4.4837 - val_accuracy: 0.6012\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 1.0884 - accuracy: 0.6902 - val_loss: 4.5388 - val_accuracy: 0.5999\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1.1073 - accuracy: 0.6846 - val_loss: 4.4772 - val_accuracy: 0.6013\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 1.0890 - accuracy: 0.6880 - val_loss: 4.5417 - val_accuracy: 0.6029\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 1.1325 - accuracy: 0.6813 - val_loss: 4.5126 - val_accuracy: 0.5979\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 1.1390 - accuracy: 0.6801 - val_loss: 4.5251 - val_accuracy: 0.6050\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 1.1380 - accuracy: 0.6801 - val_loss: 4.5219 - val_accuracy: 0.5997\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 1.0942 - accuracy: 0.6970 - val_loss: 4.5141 - val_accuracy: 0.6061\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.0730 - accuracy: 0.6813 - val_loss: 4.5563 - val_accuracy: 0.5969\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.0569 - accuracy: 0.7003 - val_loss: 4.4923 - val_accuracy: 0.6066\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 1.0612 - accuracy: 0.6902 - val_loss: 4.6186 - val_accuracy: 0.5901\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 1.0912 - accuracy: 0.6936 - val_loss: 4.4141 - val_accuracy: 0.6133\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.1165 - accuracy: 0.6835 - val_loss: 4.6970 - val_accuracy: 0.5825\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 1.1508 - accuracy: 0.6801 - val_loss: 4.4065 - val_accuracy: 0.6121\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.1278 - accuracy: 0.6768 - val_loss: 4.6688 - val_accuracy: 0.5911\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.1181 - accuracy: 0.6835 - val_loss: 4.4819 - val_accuracy: 0.6042\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.0779 - accuracy: 0.6925 - val_loss: 4.5978 - val_accuracy: 0.5974\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 1.0861 - accuracy: 0.6880 - val_loss: 4.5045 - val_accuracy: 0.6013\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.0718 - accuracy: 0.6914 - val_loss: 4.5697 - val_accuracy: 0.6020\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 1.0673 - accuracy: 0.6891 - val_loss: 4.5480 - val_accuracy: 0.5997\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 1.0576 - accuracy: 0.6992 - val_loss: 4.5427 - val_accuracy: 0.6043\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 1.0334 - accuracy: 0.6936 - val_loss: 4.5412 - val_accuracy: 0.6005\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 1.0303 - accuracy: 0.6925 - val_loss: 4.5573 - val_accuracy: 0.6019\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 1.0194 - accuracy: 0.7026 - val_loss: 4.5702 - val_accuracy: 0.5989\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.0232 - accuracy: 0.7172 - val_loss: 4.5470 - val_accuracy: 0.6042\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 1.0309 - accuracy: 0.6992 - val_loss: 4.6136 - val_accuracy: 0.5951\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 1.0409 - accuracy: 0.7015 - val_loss: 4.4887 - val_accuracy: 0.6131\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 1.0733 - accuracy: 0.6869 - val_loss: 4.6953 - val_accuracy: 0.5848\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 1.1369 - accuracy: 0.6857 - val_loss: 4.4508 - val_accuracy: 0.6140\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 1.1134 - accuracy: 0.6745 - val_loss: 4.7003 - val_accuracy: 0.5889\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 1.0814 - accuracy: 0.6936 - val_loss: 4.4623 - val_accuracy: 0.6070\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 1.0861 - accuracy: 0.6947 - val_loss: 4.6850 - val_accuracy: 0.5941\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.1099 - accuracy: 0.6846 - val_loss: 4.5445 - val_accuracy: 0.6022\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.0310 - accuracy: 0.6981 - val_loss: 4.5998 - val_accuracy: 0.6005\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 1.0258 - accuracy: 0.6970 - val_loss: 4.5742 - val_accuracy: 0.6008\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 1.0332 - accuracy: 0.6992 - val_loss: 4.6170 - val_accuracy: 0.5998\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.0197 - accuracy: 0.7071 - val_loss: 4.5926 - val_accuracy: 0.6004\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.9960 - accuracy: 0.7205 - val_loss: 4.5736 - val_accuracy: 0.6048\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.9984 - accuracy: 0.7071 - val_loss: 4.6036 - val_accuracy: 0.5988\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.0327 - accuracy: 0.6891 - val_loss: 4.6018 - val_accuracy: 0.6032\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 1.0362 - accuracy: 0.6981 - val_loss: 4.5954 - val_accuracy: 0.5993\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 1.0273 - accuracy: 0.6992 - val_loss: 4.5692 - val_accuracy: 0.6070\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.0166 - accuracy: 0.6958 - val_loss: 4.6484 - val_accuracy: 0.5933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22237209810>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_tr,y_tr[:,:-1]],y_tr.reshape(y_tr.shape[0],y_tr.shape[1],1)[:,1:], epochs=500, batch_size=256, validation_data=([x_val,y_val[:,:-1]],y_val.reshape(y_val.shape[0],y_val.shape[1],1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8366c60-4aa1-4ded-9b25-ddbb3b809577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making inference model for prediction\n",
    "\n",
    "#for encoder model\n",
    "encoder_model = Model(inputs=[encoder_input], outputs=[encoder_output,state_h,state_c])\n",
    "\n",
    "decoder_internal_state_h = Input(shape=(latent_dim,))\n",
    "decoder_internal_state_c = Input(shape=(latent_dim,))\n",
    "decoder_internal_states = [decoder_internal_state_h, decoder_internal_state_c]\n",
    "\n",
    "\n",
    "dec_emb_2 = decoder_emb_layer(decoder_input)\n",
    "decoder_output, state_h2, state_c2 = decoder_lstm(dec_emb_2, initial_state=[decoder_internal_state_h, decoder_internal_state_c])\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "#for decoder model\n",
    "decoder_model = Model(inputs=[decoder_input,decoder_internal_states], outputs=[decoder_output,state_h2,state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1b9d5a5-07ce-400d-a3e6-b43c1c9592bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d14be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = 1  # Use the index 1 for the 'start' token directly\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, state_h2, state_c2 = decoder_model.predict([target_seq, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens)\n",
    "        \n",
    "        if sampled_token_index == 0:  # Break the loop if the sampled token index is 0 (padding token)\n",
    "            break\n",
    "        \n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if sampled_token != 'end':\n",
    "            decoded_seq += ' ' + sampled_token\n",
    "        \n",
    "        if sampled_token == 'end' or len(decoded_seq.split()) >= MAX_HIN_LEN:\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        e_h, e_c = state_h2, state_c2\n",
    "    \n",
    "    return decoded_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7f15f8a-b19f-45cf-a320-bd24661339d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92b00d76-ea7f-427e-b9c7-88b9d174da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2mar(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "648ad48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Hindi sentence: start मैं आसपड़ोस में रहता हूँ। end \n",
      "Real Marwadi translation:  मैं अट कने ही रु \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted summary:  मन रो चोखो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह बीमार नहीं हो सकता। end \n",
      "Real Marwadi translation:  बो बीमार कोनी हु सके \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  करो बिंया है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start उसको पैसों की कमी थी। end \n",
      "Real Marwadi translation:  बिन रिप्या की कमी ही। \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  रिप्या रो सोरो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे पता है उसने क्यों किया था। end \n",
      "Real Marwadi translation:  मने धयन है बि काई करियो \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक में हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह बस आता ही होगा। end \n",
      "Real Marwadi translation:  बो बस आतो ही हुगो \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक में ही है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैं तुम्हारे जितना लम्बा हूँ। end \n",
      "Real Marwadi translation:  मैं थारे जीतो लम्बो हू \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted summary:  रिप्या रो सोरो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start कर भला तो हो भला। end \n",
      "Real Marwadi translation:  करो भलो हुई भलो \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted summary:  भलो हुई\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैं चाहता था कि वह जीत जाए। end \n",
      "Real Marwadi translation:  में चाहतो हो कि बो जीत जावे \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक थारी हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start उसको फ़ुटबॉल खेलना अच्छा लगता है। end \n",
      "Real Marwadi translation:  बिन फ़ुटबॉल खेलनो चोखो लागे \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  रिप्या रो चोखो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start उसने मुझे अपना कमरा दिखाया। end \n",
      "Real Marwadi translation:  बिण मन खुदको कमरो दिखायो \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted summary:  रिप्या रो चोखो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे नहीं पता। end \n",
      "Real Marwadi translation:  मन कोनी ध्यान \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  कियान है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैं कभी वापस नहीं आऊँगा। end \n",
      "Real Marwadi translation:  मैं कद पाछो कोनी आऊं \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  तने कद कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे उसका पता पता है। end \n",
      "Real Marwadi translation:  मने बिरो पतो ध्यान है \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक में हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start आम end \n",
      "Real Marwadi translation:  आंबौ \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Input Hindi sentence: start मेरी एक पुराने दोस्त से मुलाक़ात हुई। end \n",
      "Real Marwadi translation:  मैं एक पुराने दोस्त हु मिलयो \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक थारी हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start यह रास्ता बहुत पतला है। end \n",
      "Real Marwadi translation:  ओ रास्तों कल्डो पतलो है \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted summary:  रिप्या रो चोखो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मेरे ख़याल से तुम सही हो। end \n",
      "Real Marwadi translation:  मन लागे तू ठीक है \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  रिप्या रो चोखो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह ताकतवर है। end \n",
      "Real Marwadi translation:  बो हेन्टो है \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  कियान है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start सब लोग कैसे हैं end \n",
      "Real Marwadi translation:  सगला कियान है \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted summary:  कियान है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मेरे दोस्त कैसे हो end \n",
      "Real Marwadi translation:  म्हारा भाईला क्या हाल है थारा \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  एक थारी हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह तेल में पका हुआ है। end \n",
      "Real Marwadi translation:  ओ तेल मे पकुङो है \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  एक में हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start तुम्हारी किताब कौनसी है end \n",
      "Real Marwadi translation:  थारी किताब किसी है \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  सहला अरबी है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start ये कुत्ते बड़े हैं। end \n",
      "Real Marwadi translation:  ओ कुत्तों मोटो है \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  घर मोटो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start उसे बहुत अकेलापन महसूस हुआ। end \n",
      "Real Marwadi translation:  बिने कल्डो ऐकलो लाग्यो \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicted summary:  ओर तेज कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start हम बात कर सकते हैं क्या end \n",
      "Real Marwadi translation:  आम्पा बात कर सका \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  चाकु कर कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे कुत्ते अच्छे लगते हैं। end \n",
      "Real Marwadi translation:  मन कुटाया चोको लागे \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  घर ही है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह गाने लगी। end \n",
      "Real Marwadi translation:  बा गण लागी \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted summary:  कियान ध्यान\n",
      "\n",
      "\n",
      "Input Hindi sentence: start तुम्हारे कोई भाई हैं क्या end \n",
      "Real Marwadi translation:  थारे कोई भाई है की \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted summary:  रिप्या की ज़रूरत है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैं मानता हूँ कि मैं ग़लत था। end \n",
      "Real Marwadi translation:  मैं मानू में गलत हो \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक में हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start एक बार और प्रयत्न करो। end \n",
      "Real Marwadi translation:  ऐकर ओर कोशिश कर \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  फ़ोन कर कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start यह एक बहुत अच्छा सवाल है। end \n",
      "Real Marwadi translation:  ओ एक कल्डो चोखो सवाल है \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक कल्डो चोखो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start हम अरबी पढ़तें हैं। end \n",
      "Real Marwadi translation:  मैं सहला अरबी पढ़ा \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  करो बिंया है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start चले जाओ end \n",
      "Real Marwadi translation:  भाग जा \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह देशद्रोही बन गया। end \n",
      "Real Marwadi translation:  बो देशद्रोही बणगो \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  भूल बणगो\n",
      "\n",
      "\n",
      "Input Hindi sentence: start तुम कब लौट कर आओगे end \n",
      "Real Marwadi translation:  तू पाचो कद आई \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  मने फ़ोन कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैंने उसके बाहर जाने की आवाज़ सुनी। end \n",
      "Real Marwadi translation:  मैं बिरे बारे जाऊन को आवाज सुनी \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted summary:  एक थारी हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे बहुत प्यास लगी है। end \n",
      "Real Marwadi translation:  मन कल्डी तीस लागुड़ी है \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  रिप्या रो सोरो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैं तुम्हें फ़ोन करूँगा। end \n",
      "Real Marwadi translation:  मैं तने फ़ोन करूँ। \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicted summary:  मने फ़ोन कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start काश मैं तुम्हारी मदद कर सकता। end \n",
      "Real Marwadi translation:  काश मैं थारी मदद कर सकतो \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted summary:  एक कल्डो हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start तुम किस समय घर जाती हो end \n",
      "Real Marwadi translation:  तू किता बजी घर जावे \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted summary:  रिप्या की चोको है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैं भी बॉस्टन में ही रहता हूँ। end \n",
      "Real Marwadi translation:  मै भी बॉस्टन में ही रु \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  एक थारी हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start वह पार्क में खो गया। end \n",
      "Real Marwadi translation:  बो पार्क में गमगो \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  रिप्या ही है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मैंने फ़ोन कर लिया है। end \n",
      "Real Marwadi translation:  में फ़ोन कर लियो \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  फ़ोन कर कर\n",
      "\n",
      "\n",
      "Input Hindi sentence: start इस घर में छः कमरे हैं। end \n",
      "Real Marwadi translation:  ई घर में छे कमरा है \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  एक थारी हु हु है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start तुम क्या कर रहे थे end \n",
      "Real Marwadi translation:  तू काई करे हो \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  सगळा कोशिश उबगा\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे उल्टी आ रही है। end \n",
      "Real Marwadi translation:  मने उल्टी आवे \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted summary:  उल्टी हुई\n",
      "\n",
      "\n",
      "Input Hindi sentence: start अभी क्या समय हो रहा है end \n",
      "Real Marwadi translation:  अब किती भजूड़ी है \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted summary:  सहला अरबी है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start मुझे मछली से एलर्जी है। end \n",
      "Real Marwadi translation:  मन मछली हु एलर्जी है \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  रिप्या रो सोरो है\n",
      "\n",
      "\n",
      "Input Hindi sentence: start हम सब एकसाथ खड़े हो गए। end \n",
      "Real Marwadi translation:  ऐ सगळा सागे उबगा \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  अंग्रेज़ी कर उबगा\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,50):  # Adjust the range based on the number of examples you want to test\n",
    "    print('Input Hindi sentence:', seq2text(x_tr[i]))\n",
    "    print(\"Real Marwadi translation: \", seq2mar(y_tr[i]))\n",
    "    print(\"Predicted summary:\", decode_sequence(x_tr[i].reshape(1, MAX_HIN_LEN)))\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
